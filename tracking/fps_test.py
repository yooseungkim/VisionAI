import cv2
import time
import torch
from ultralytics import YOLO

# --- ì„¤ì • ---
video_path = "datasets/parking3.mp4"
model_name = "yolo11m-seg.pt" # ë¬´ê±°ìš´ ëª¨ë¸
BATCH_SIZE = 16  # 4090ì˜ VRAMì„ ë¯¿ê³  16ì¥ì”© í•œ ë²ˆì— ì²˜ë¦¬

# --- ì¤€ë¹„ ---
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = YOLO(model_name).to(device)
cap = cv2.VideoCapture(video_path)

if not cap.isOpened():
    print("Video open failed!")
    exit()

print(f"ğŸ”¥ MAX PERFORMANCE TEST ğŸ”¥")
print(f"Device: {device}, Model: {model_name}, Batch: {BATCH_SIZE}")
print("Logic/Drawing/Saving disabled. Pure Inference Speed Test.")

frames_buffer = []
total_frames = 0
start_time = time.time()

try:
    while True:
        # 1. BATCH_SIZEë§Œí¼ í”„ë ˆì„ ëª¨ìœ¼ê¸° (CPU ì½ê¸°)
        frames_buffer = []
        for _ in range(BATCH_SIZE):
            ret, frame = cap.read()
            if not ret:
                break
            frames_buffer.append(frame)
        
        if not frames_buffer:
            break
        
        current_batch_size = len(frames_buffer)
        
        # 2. ë°°ì¹˜ ì¶”ë¡  (GPU í•œ ë°© ì²˜ë¦¬)
        # verbose=Falseë¡œ ì½˜ì†” ì¶œë ¥ ë”
        results = model(frames_buffer, verbose=False, stream=False)
        
        # (ì—¬ê¸°ì„œ resultsë¥¼ íŒŒì‹±í•˜ëŠ” ë¡œì§ì´ ë“¤ì–´ê°€ë©´ ì†ë„ê°€ ë–¨ì–´ì§)
        # ì§€ê¸ˆì€ ìˆœìˆ˜ ì¶”ë¡  ì†ë„ë§Œ ì¸¡ì •
        
        total_frames += current_batch_size
        
        # 3. ì†ë„ ëª¨ë‹ˆí„°ë§
        if total_frames % (BATCH_SIZE * 5) == 0:
            elapsed = time.time() - start_time
            fps = total_frames / elapsed
            print(f"Processed {total_frames} frames. Current FPS: {fps:.2f}")

except KeyboardInterrupt:
    print("Stopped.")

final_elapsed = time.time() - start_time
print(f"DONE. Average Inference FPS: {total_frames / final_elapsed:.2f}")

cap.release()